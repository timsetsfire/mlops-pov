{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files were overwritten: {'/opt/fit_output_dir/create_data.py', '/opt/fit_output_dir/custom_model.py', '/opt/fit_output_dir/feature_detail.yaml', '/opt/fit_output_dir/model-config.yaml', '/opt/fit_output_dir/custom.py', '/opt/fit_output_dir/README.md', '/opt/fit_output_dir/create_pipeline.py', '/opt/fit_output_dir/schema.json', '/opt/fit_output_dir/artifact.pkl'}\n",
      "Success ðŸŽ‰\n",
      "WARNING: looks like host DRUM version doesn't match container DRUM version. This can lead to unexpected behavior.\n",
      "Host DRUM version: 1.4.4\n",
      "Container DRUM version: \n",
      "the input device is not a TTY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "drum fit --code-dir ./model \\\n",
    "--input data/10K_Lending_Club_Loans_utf-8.csv \\\n",
    "--output ./model \\\n",
    "--target-type binary \\\n",
    "--target is_bad \\\n",
    "--docker env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected perf-test mode\n",
      "DRUM performance test\n",
      "Model:      /Users/timothy.whittaker/Desktop/git/ford-mlops/model\n",
      "Data:       /Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_LC_short.csv\n",
      "# Features: 35\n",
      "\u001b[m\u001b[?7h\u001b[4l\u001b>\u001b7\u001b[r\u001b[?1;3;4;6l\u001b8Preparing test data...\n",
      "Running drum using: [drum server --code-dir /Users/timothy.whittaker/Desktop/git/ford-mlops/model --address localhost:59718 --logging-level warning --show-perf --target-type binary --positive-class-label 1 --negative-class-label 0 --docker env]\n",
      "\n",
      "\n",
      "\n",
      "Running test case with timeout: 180\n",
      "Running test case: 550 bytes - 1 samples, 100 iterations\n",
      "Running test case with timeout: 180\n",
      "Running test case: 0.1MB - 190 samples, 50 iterations\n",
      "Running test case with timeout: 180\n",
      "Running test case: 10MB - 19051 samples, 5 iterations\n",
      "Running test case with timeout: 180\n",
      "Running test case: 50MB - 95256 samples, 1 iterations\n",
      "Test is done stopping drum server\n",
      "\n",
      " size    sample   iters    min     avg     max    contai   conta   conta   total\n",
      "           s                                       ner     iner    iner    physi\n",
      "                                                   used     max    limit    cal \n",
      "                                                   (MB)    used    (MB)    (MB) \n",
      "                                                           (MB)                 \n",
      "================================================================================\n",
      "550           1     100   0.066   0.077   0.117   137.03   137.3   87960   3940.\n",
      "bytes                                                  5      48   93022     836\n",
      "                                                                   207.9        \n",
      "                                                                      96        \n",
      "0.1MB       190      50   0.090   0.102   0.129   134.25   137.3   87960   3940.\n",
      "                                                       8      48   93022     836\n",
      "                                                                   207.9        \n",
      "                                                                      96        \n",
      "10MB      19051       5   1.203   1.319   1.537   141.06   190.3   87960   3940.\n",
      "                                                       6      83   93022     836\n",
      "                                                                   207.9        \n",
      "                                                                      96        \n",
      "50MB      95256       1   9.544   9.544   9.544   148.67   358.9   87960   3940.\n",
      "                                                       6      30   93022     836\n",
      "                                                                   207.9        \n",
      "                                                                      96        \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "drum perf-test \\\n",
    "--code-dir ./model \\\n",
    "--input \"data/10K_LC_short.csv\" \\\n",
    "--target-type binary \\\n",
    "--positive-class-label 1 \\\n",
    "--negative-class-label 0 \\\n",
    "--docker env \\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: invalid mode: /opt/input.csv.\n",
      "See 'docker run --help'.\n",
      "2020-12-16 20:45:18,951 ERROR drum:  Error from docker process: 125\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 96, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 289, in run\n",
      "    self._run_fit_and_predictions_pipelines_in_mlpiper()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 559, in _run_fit_and_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 138, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 100, in _materialize\n",
      "    predictions = self._predictor.predict(input_filename)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 52, in predict\n",
      "    predictions = self._model_adapter.predict(input_filename, model=self._model, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 326, in predict\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 322, in predict\n",
      "    data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/opt/model/custom.py\", line 82, in transform\n",
      "    data = model.preprocess(data)\n",
      "  File \"/opt/model/custom_model.py\", line 37, in preprocess\n",
      "    data = process_data(self.code_dir, X)\n",
      "  File \"/opt/model/create_data.py\", line 40, in process_data\n",
      "    data = clean_up(code_dir, data)  \n",
      "  File \"/opt/model/create_data.py\", line 23, in clean_up\n",
      "    data[\"int_rate\"] = data[\"int_rate\"].apply(lambda x: x.replace(\"%\", \"\")).astype(float)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/series.py\", line 4200, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2388, in pandas._libs.lib.map_infer\n",
      "  File \"/opt/model/create_data.py\", line 23, in <lambda>\n",
      "    data[\"int_rate\"] = data[\"int_rate\"].apply(lambda x: x.replace(\"%\", \"\")).astype(float)\n",
      "AttributeError: Model transform hook failed to transform dataset: 'float' object has no attribute 'replace'\n",
      "2020-12-16 20:45:44,432 ERROR drum:  Error from docker process: 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 96, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 289, in run\n",
      "    self._run_fit_and_predictions_pipelines_in_mlpiper()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 559, in _run_fit_and_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 138, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 100, in _materialize\n",
      "    predictions = self._predictor.predict(input_filename)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 52, in predict\n",
      "    predictions = self._model_adapter.predict(input_filename, model=self._model, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 326, in predict\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 322, in predict\n",
      "    data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/opt/model/custom.py\", line 82, in transform\n",
      "    data = model.preprocess(data)\n",
      "  File \"/opt/model/custom_model.py\", line 37, in preprocess\n",
      "    data = process_data(self.code_dir, X)\n",
      "  File \"/opt/model/create_data.py\", line 38, in process_data\n",
      "    data = join_state_info(code_dir, data) \n",
      "  File \"/opt/model/create_data.py\", line 9, in join_state_info\n",
      "    df = data.merge(state_info, how=\"left\", left_on = [\"zip_code\", \"addr_state\"], right_on = [\"zip\", \"addr_state\"])\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 7952, in merge\n",
      "    validate=validate,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 87, in merge\n",
      "    validate=validate,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 656, in __init__\n",
      "    self._maybe_coerce_merge_keys()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 1165, in _maybe_coerce_merge_keys\n",
      "    raise ValueError(msg)\n",
      "ValueError: Model transform hook failed to transform dataset: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat\n",
      "2020-12-16 20:46:59,565 ERROR drum:  Error from docker process: 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 96, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 289, in run\n",
      "    self._run_fit_and_predictions_pipelines_in_mlpiper()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 559, in _run_fit_and_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 138, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 100, in _materialize\n",
      "    predictions = self._predictor.predict(input_filename)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 52, in predict\n",
      "    predictions = self._model_adapter.predict(input_filename, model=self._model, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 326, in predict\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/usr/local/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 322, in predict\n",
      "    data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/opt/model/custom.py\", line 82, in transform\n",
      "    data = model.preprocess(data)\n",
      "  File \"/opt/model/custom_model.py\", line 37, in preprocess\n",
      "    data = process_data(self.code_dir, X)\n",
      "  File \"/opt/model/create_data.py\", line 38, in process_data\n",
      "    data = join_state_info(code_dir, data) \n",
      "  File \"/opt/model/create_data.py\", line 9, in join_state_info\n",
      "    df = data.merge(state_info, how=\"left\", left_on = [\"zip_code\", \"addr_state\"], right_on = [\"zip\", \"addr_state\"])\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 7952, in merge\n",
      "    validate=validate,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 87, in merge\n",
      "    validate=validate,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 656, in __init__\n",
      "    self._maybe_coerce_merge_keys()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/reshape/merge.py\", line 1165, in _maybe_coerce_merge_keys\n",
      "    raise ValueError(msg)\n",
      "ValueError: Model transform hook failed to transform dataset: You are trying to merge on float64 and object columns. If you wish to proceed you should use pd.concat\n",
      "2020-12-16 20:47:04,740 ERROR drum:  Error from docker process: 1\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "drum validation \\\n",
    "--code-dir ./model \\\n",
    "--input \"data/10K_LC_short.csv\" \\\n",
    "--target-type binary \\\n",
    "--positive-class-label 1 \\\n",
    "--negative-class-label 0 \\\n",
    "--docker env > validation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input device is not a TTY\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Validation checks results\r\n",
      "      Test case         Status                       Details                    \r\n",
      "================================================================================\r\n",
      "Null value imputation   FAILED   Null value imputation check performs check by  \r\n",
      "                                 imputing each feature with NaN value. If check \r\n",
      "                                 fails for a feature, test dataset is saved in  \r\n",
      "                                 /tmp/drum_validation_checks_. Make sure to     \r\n",
      "                                 delete those folders if it takes too much      \r\n",
      "                                 space.                                         \r\n",
      "                                                                                \r\n",
      "                                 Failed feature                          Dataset\r\n",
      "                                 filename                                       \r\n",
      "                                 ===============================================\r\n",
      "                                 =================================              \r\n",
      "                                 Unnamed: 0       /tmp/drum_validation_checks_s4\r\n",
      "                                 s9yat0/null_value_imputation_Unna              \r\n",
      "                                                  med: 0_it28hj0r               \r\n",
      "                                 int_rate         /tmp/drum_validation_checks_s4\r\n",
      "                                 s9yat0/null_value_imputation_int_              \r\n",
      "                                                  rate_6pmwfa0j                 \r\n",
      "                                 zip_code         /tmp/drum_validation_checks_s4\r\n",
      "                                 s9yat0/null_value_imputation_zip_              \r\n",
      "                                                  code_yrrav5n8                 \r\n",
      "                                 addr_state       /tmp/drum_validation_checks_s4\r\n",
      "                                 s9yat0/null_value_imputation_addr              \r\n",
      "                                                  _state_cr32e9qu               \r\n"
     ]
    }
   ],
   "source": [
    "! tail -n 30 validation.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected score mode\n",
      "Detected /opt/model/custom.py .. trying to load hooks\n",
      "Finished loading model, total used 100 iterations\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32mComponent: generic_predictor\u001b[0m\n",
      "\u001b[32mLanguage:  Python\u001b[0m\n",
      "\u001b[32mOutput:\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "{'target_type': <TargetType.BINARY: 'binary'>, 'positive_class_label': 'pos_class_prediction', 'negative_class_label': 'neg_class_prediction'}\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mRuntime:    0.1 sec\u001b[0m\n",
      "\u001b[32mNR outputs: 0\u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "docker command: [docker run --rm --interactive --user $(id -u):$(id -g)   -v /Users/timothy.whittaker/Desktop/git/ford-mlops/model:/opt/model -v \"/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_LC_short.csv\":/opt/input.csv -v \"/Users/timothy.whittaker/Desktop/git/ford-mlops/data/predictions.csv\":/opt/output.csv sha256:d796fdc6e00d9b1b32519ccd3e39b93d648769b66bdbdf255aa4f33a3ca24b37 drum score --code-dir /opt/model --target-type binary --positive-class-label pos_class_prediction --negative-class-label neg_class_prediction --input /opt/input.csv --verbose --output /opt/output.csv]\n",
      "Checking DRUM version in container...\n",
      "WARNING: looks like host DRUM version doesn't match container DRUM version. This can lead to unexpected behavior.\n",
      "Host DRUM version: 1.4.4\n",
      "Container DRUM version: \n",
      "the input device is not a TTY\n",
      "\n",
      "--------------------\n",
      "---------- retcode: 0 ----------\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "drum score \\\n",
    "--code-dir ./model \\\n",
    "--target-type binary \\\n",
    "--positive-class-label pos_class_prediction \\\n",
    "--negative-class-label neg_class_prediction \\\n",
    "--input data/10K_LC_short.csv \\\n",
    "--docker env \\\n",
    "--verbose --output data/predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_class_prediction,pos_class_prediction\r\n",
      "0.9816415360226007,0.01835846397739924\r\n",
      "0.8722987977456673,0.12770120225433262\r\n",
      "0.9798190190554988,0.020180980944501145\r\n",
      "0.9299558044221623,0.07004419557783767\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Scoring Unstructured Model\n",
    "\n",
    "Returns Predictions and SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected score mode\n",
      "Detected /opt/model/custom.py .. trying to load hooks\n",
      "Finished loading model, total used 100 iterations\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32mComponent: generic_predictor\u001b[0m\n",
      "\u001b[32mLanguage:  Python\u001b[0m\n",
      "\u001b[32mOutput:\u001b[0m\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "Incoming content type params:  {'mimetype': 'application/text'}\n",
      "Incoming data type:  <class 'bytes'>\n",
      "Incoming query params:  {}\n",
      "\u001b[32m------------------------------------------------------------\u001b[0m\n",
      "\u001b[32mRuntime:    0.2 sec\u001b[0m\n",
      "\u001b[32mNR outputs: 0\u001b[0m\n",
      "\u001b[32m============================================================\u001b[0m\n",
      "\u001b[32m \u001b[0m\n",
      "docker command: [docker run --rm --interactive --user $(id -u):$(id -g)   -v /Users/timothy.whittaker/Desktop/git/ford-mlops/model:/opt/model -v \"/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_LC_short.csv\":/opt/input.csv -v \"/Users/timothy.whittaker/Desktop/git/ford-mlops/data/predictions.json\":/opt/output.csv sha256:d796fdc6e00d9b1b32519ccd3e39b93d648769b66bdbdf255aa4f33a3ca24b37 drum score --code-dir /opt/model --input /opt/input.csv --target-type unstructured --content-type application/text --verbose --output /opt/output.csv]\n",
      "Checking DRUM version in container...\n",
      "WARNING: looks like host DRUM version doesn't match container DRUM version. This can lead to unexpected behavior.\n",
      "Host DRUM version: 1.4.4\n",
      "Container DRUM version: \n",
      "the input device is not a TTY\n",
      "\n",
      "--------------------\n",
      "---------- retcode: 0 ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "drum score \\\n",
    "--code-dir ./model \\\n",
    "--input \"data/10K_LC_short.csv\" \\\n",
    "--target-type unstructured \\\n",
    "--content-type application/text \\\n",
    "--docker env \\\n",
    "--verbose --output data/predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': {'negative_class_label_prob': 0.9816415360226007,\n",
      "                 'positive_class_label_prob': 0.01835846397739924},\n",
      " 'shap_values': {'POS_CLASS_SHAP_addr_state': 0.008390547232085098,\n",
      "                 'POS_CLASS_SHAP_addr_state_name': -0.01587483936197775,\n",
      "                 'POS_CLASS_SHAP_annual_inc': 0.08800024892580516,\n",
      "                 'POS_CLASS_SHAP_delinq_2yrs': -0.0036656212456457485,\n",
      "                 'POS_CLASS_SHAP_dti': 0.047127242530700095,\n",
      "                 'POS_CLASS_SHAP_earliest_cr_line day of week': -0.04021584397331488,\n",
      "                 'POS_CLASS_SHAP_earliest_cr_line month of year': -0.17162178620756163,\n",
      "                 'POS_CLASS_SHAP_emp_length': -0.1137186917067495,\n",
      "                 'POS_CLASS_SHAP_emp_title': -0.02926689870639889,\n",
      "                 'POS_CLASS_SHAP_funded_amnt': 0.017315288502232875,\n",
      "                 'POS_CLASS_SHAP_grade': 0.02069466102221773,\n",
      "                 'POS_CLASS_SHAP_home_ownership': -0.01047770841421593,\n",
      "                 'POS_CLASS_SHAP_initial_list_status': 0.0,\n",
      "                 'POS_CLASS_SHAP_inq_last_6mths': -0.005890797155705319,\n",
      "                 'POS_CLASS_SHAP_installment': 0.23140989229405434,\n",
      "                 'POS_CLASS_SHAP_int_rate': -1.0789047448233968,\n",
      "                 'POS_CLASS_SHAP_loan_amnt': -0.009109203520324693,\n",
      "                 'POS_CLASS_SHAP_mths_since_last_delinq': 0.025968513374944102,\n",
      "                 'POS_CLASS_SHAP_mths_since_last_major_derog': 0.0,\n",
      "                 'POS_CLASS_SHAP_mths_since_last_record': 0.004688977322069683,\n",
      "                 'POS_CLASS_SHAP_open_acc': -0.03911455021298336,\n",
      "                 'POS_CLASS_SHAP_policy_code': 0.0,\n",
      "                 'POS_CLASS_SHAP_pub_rec': 0.0006930797279572871,\n",
      "                 'POS_CLASS_SHAP_purpose': -0.0037891869645002344,\n",
      "                 'POS_CLASS_SHAP_pymnt_plan': 0.0,\n",
      "                 'POS_CLASS_SHAP_revol_bal': 0.015349826175102327,\n",
      "                 'POS_CLASS_SHAP_revol_util': -0.15413861684325536,\n",
      "                 'POS_CLASS_SHAP_state_id': -0.003966838370120463,\n",
      "                 'POS_CLASS_SHAP_sub_grade': 0.04560375337099718,\n",
      "                 'POS_CLASS_SHAP_term': 0.46124440344232415,\n",
      "                 'POS_CLASS_SHAP_title': -0.48261776715986604,\n",
      "                 'POS_CLASS_SHAP_total_acc': 0.026817838147982234,\n",
      "                 'POS_CLASS_SHAP_verification_status': -0.04083633596438613,\n",
      "                 'POS_CLASS_SHAP_zip_code': -0.15840084498953713}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "d = json.load(open(\"data/predictions.json\", \"rb\"))\n",
    "pprint.pprint(d[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_server = [\n",
    "    \"drum\", \"server\",\n",
    "    \"--code-dir\",\"./model\", \n",
    "    \"--address\", \"0.0.0.0:6789\", \n",
    "    \"--show-perf\",\n",
    "    \"--target-type\", \"binary\",\n",
    "    \"--logging-level\", \"info\",\n",
    "    \"--show-stacktrace\",\n",
    "    \"--verbose\", \n",
    "    \"--docker\", \"env\"\n",
    "]\n",
    "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## snoozing before pinging the server to give it time to actually start\n",
    "time.sleep(5)\n",
    "print('check status')\n",
    "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Server shutting down...'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## shutdown\n",
    "requests.request(\"POST\", \"http://0.0.0.0:6789/shutdown/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Detected REST server mode - this is an advanced option\\n',\n",
       " b'Detected /opt/model/custom.py .. trying to load hooks\\n',\n",
       " b'Finished loading model, total used 100 iterations\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m \\x1b[0m\\n',\n",
       " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
       " b'\\x1b[32mComponent: prediction_server\\x1b[0m\\n',\n",
       " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
       " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
       " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n',\n",
       " b' * Serving Flask app \"datarobot_drum.drum.server\" (lazy loading)\\n',\n",
       " b' * Environment: production\\n',\n",
       " b'   WARNING: This is a development server. Do not use it in a production deployment.\\n',\n",
       " b'   Use a production WSGI server instead.\\n',\n",
       " b' * Debug mode: off\\n',\n",
       " b'docker command: [docker run --rm --interactive --user $(id -u):$(id -g)   -v /Users/timothy.whittaker/Desktop/git/ford-mlops/model:/opt/model -p 6789:6789 sha256:d796fdc6e00d9b1b32519ccd3e39b93d648769b66bdbdf255aa4f33a3ca24b37 drum server --code-dir /opt/model --address 0.0.0.0:6789 --show-perf --target-type binary --logging-level info --show-stacktrace --verbose]\\n',\n",
       " b'Checking DRUM version in container...\\n',\n",
       " b\"WARNING: looks like host DRUM version doesn't match container DRUM version. This can lead to unexpected behavior.\\n\",\n",
       " b'Host DRUM version: 1.4.4\\n',\n",
       " b'Container DRUM version: \\n',\n",
       " b'the input device is not a TTY\\n',\n",
       " b'\\n',\n",
       " b'--------------------\\n',\n",
       " b'---------- retcode: 1 ----------\\n']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_server.terminate()\n",
    "inference_server.stdout.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Artifacts and Environment to DataRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(env_dir='./env', logging_level='INFO', max_wait=600, model_dir='./model', update_env=True)\n",
      "__main__ - INFO - 2020-12-16 21:04:30,492 - Namespace(env_dir='./env', logging_level='INFO', max_wait=600, model_dir='./model', update_env=True)\n",
      "__main__ - INFO - 2020-12-16 21:04:30,928 - load model config\n",
      "__main__ - INFO - 2020-12-16 21:04:30,933 - {'description': None, 'language': 'Python', 'majorVersion': True, 'name': 'lgbm-classifier', 'negativeClassLabel': 0, 'positiveClassLabel': 1, 'predictionThreshold': 0.17, 'targetName': 'is_bad', 'targetType': 'binary', 'testData': '/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_LC_short.csv', 'trainingData': '/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_Lending_Club_Loans_utf-8.csv', 'type': 'inference', 'versionId': None, 'environmentID': '5fda0b23d33aebb30a492f74', 'environmentVersionID': '5fda0b242d986b76e2d33bf8'}\n",
      "__main__ - INFO - 2020-12-16 21:04:30,933 - create new inference model\n",
      "__main__ - INFO - 2020-12-16 21:04:31,351 - creating a new model version\n",
      "__main__ - INFO - 2020-12-16 21:04:37,078 - update model metadata yaml\n",
      "__main__ - INFO - 2020-12-16 21:04:37,078 - {'description': None, 'language': 'Python', 'majorVersion': True, 'name': 'lgbm-classifier', 'negativeClassLabel': 0, 'positiveClassLabel': 1, 'predictionThreshold': 0.17, 'targetName': 'is_bad', 'targetType': 'binary', 'testData': '/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_LC_short.csv', 'trainingData': '/Users/timothy.whittaker/Desktop/git/ford-mlops/data/10K_Lending_Club_Loans_utf-8.csv', 'type': 'inference', 'versionId': None, 'environmentID': '5fda0b23d33aebb30a492f74', 'environmentVersionID': '5fda0b242d986b76e2d33bf8', 'id': '5fdabcafbe83ab04a68cfc1d', 'modelVersionID': '5fdabcb0c1e1a858e02d9f0c'}\n"
     ]
    }
   ],
   "source": [
    "!python push.py --env-dir ./env --model-dir ./model --logging-level INFO --max-wait 600 --update-env True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model in DataRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(logging_level='INFO', max_wait=600, model_dir='./model')\n",
      "__main__ - INFO - 2020-12-16 21:05:38,784 - Namespace(logging_level='INFO', max_wait=600, model_dir='./model')\n",
      "__main__ - INFO - 2020-12-16 21:05:38,785 - loading model config\n",
      "__main__ - INFO - 2020-12-16 21:05:38,788 - loading dataset to ai catalog\n",
      "__main__ - INFO - 2020-12-16 21:06:21,218 - starting custom model test\n",
      "__main__ - INFO - 2020-12-16 21:11:01,712 - test complete\n",
      "__main__ - INFO - 2020-12-16 21:11:01,713 - warning ðŸ˜±\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Test: error_check\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Status: succeeded\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Message: \n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Test: null_value_imputation\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Status: warning\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Message: Model cannot impute null values for the following columns:\n",
      "int_rate, zip_code, addr_state\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Test: long_running_service\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Status: succeeded\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Message: \n",
      "__main__ - ERROR - 2020-12-16 21:11:01,713 - Test: side_effects\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,714 - Status: succeeded\n",
      "__main__ - ERROR - 2020-12-16 21:11:01,714 - Message: \n"
     ]
    }
   ],
   "source": [
    "!python test.py --model-dir ./model --logging-level INFO --max-wait 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
